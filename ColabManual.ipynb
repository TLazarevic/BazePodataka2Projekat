{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cQjDQPZBl_fgY7Kj2ZnrS0tO5z0krvrx",
      "authorship_tag": "ABX9TyPPnNTf4eteXIEXvPK43Ha8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TLazarevic/BazePodataka2Projekat/blob/master/ColabManual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzoKPmuxlwS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f019a01e-ef5b-4294-8b1c-9b9df417f35d"
      },
      "source": [
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from random import choice, sample\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import svm, metrics\n",
        "import pickle\n",
        "from imutils import face_utils\n",
        "import dlib\n",
        "import matplotlib.pyplot  as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# ------------------------------- DATA --------------------------------\n",
        "\n",
        "val_families_list = [\"F09\", \"F04\", \"F08\", \"F06\", \"F02\"]\n",
        "\n",
        "\n",
        "def get_train_val(family_name):\n",
        "    train_file_path = \"drive/My Drive/train_relationships.csv\"\n",
        "    train_folders_path = \"drive/My Drive/train/\"\n",
        "    # train_file_path = \"dataset/train_pairs_new.xlsx\"\n",
        "    # train_folders_path = \"dataset/train_new/\"\n",
        "    val_families = family_name\n",
        "\n",
        "    all_images = glob(train_folders_path + \"*/*/*.jpg\")\n",
        "    all_images = [x.replace('\\\\', '/') for x in all_images]\n",
        "    train_images = [x for x in all_images if val_families not in x]\n",
        "    val_images = [x for x in all_images if val_families in x]\n",
        "\n",
        "    train_person_to_images_map = defaultdict(list)\n",
        "\n",
        "    ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
        "\n",
        "    for x in train_images:\n",
        "        train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
        "\n",
        "    val_person_to_images_map = defaultdict(list)\n",
        "\n",
        "    for x in val_images:\n",
        "        val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
        "    #     relationships = pd.read_excel(train_file_path)\n",
        "    # relationships = pd.read_excel(train_file_path)\n",
        "    relationships = pd.read_csv(train_file_path)\n",
        "    relationships = list(zip(relationships.p1.values, relationships.p2.values))\n",
        "    relationships = [x for x in relationships if x[0] in ppl and x[1] in ppl]\n",
        "\n",
        "    train = [x for x in relationships if val_families not in x[0]]\n",
        "    val = [x for x in relationships if val_families in x[0]]\n",
        "    return train, val, train_person_to_images_map, val_person_to_images_map\n",
        "\n",
        "def euclidianDistance(a,b):\n",
        "    return np.math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
        "\n",
        "def angle(a,b,c):\n",
        "    angle = np.math.degrees(np.math.atan2(c[1] - b[1], c[0] - b[0]) - np.math.atan2(a[1] - b[1], a[0] - b[0]))\n",
        "    return angle + 360 if angle < 0 else angle\n",
        "\n",
        "def extractFeatures(dots, img, imgcolor):\n",
        "\n",
        "    features=[]\n",
        "\n",
        "    #skaliranje svih tacaka u odnosu na sirinu lica:\n",
        "    scaleFactor=dots[15][0]-dots[1][0]\n",
        "\n",
        "    # distances\n",
        "\n",
        "    features.append(euclidianDistance(dots[39],dots[27])) # eye2nose distance\n",
        "    # features.append(euclidianDistance(dots[40],dots[48])) # eye2mouth distance\n",
        "    # features.append(euclidianDistance(dots[39],dots[42])) # eye distance\n",
        "    features.append(euclidianDistance(dots[33],dots[51])) # nose-to-mouth distance\n",
        "\n",
        "    for f in features:\n",
        "        f = f/scaleFactor\n",
        "\n",
        "    # colors\n",
        "\n",
        "    mouth_left = dots[48]\n",
        "    mouth_right = dots[54]\n",
        "    mouth_up = dots[50]\n",
        "    mouth_down = dots[57]\n",
        "    features.append(img[dots[29][0],dots[29][1]]) #skin color taken from nose center point\n",
        "\n",
        "    right_eye1 = dots[37]\n",
        "    right_eye2 = dots[38]\n",
        "    right_eye3 = dots[41]\n",
        "    right_eye4 = dots[40]\n",
        "    right_eye = imgcolor[right_eye2[1]:right_eye4[1],right_eye1[0]:right_eye2[0]]\n",
        "    xCenter = int(right_eye1[0] + (right_eye2[0] - right_eye1[0])/2)\n",
        "    yCenter = int(right_eye2[1] + (right_eye4[1] - right_eye2[1])/2)\n",
        "    right_eye_color = imgcolor[xCenter,yCenter,:]\n",
        "    features.append(right_eye_color[0])\n",
        "    features.append(right_eye_color[1])\n",
        "    features.append(right_eye_color[2])\n",
        "\n",
        "    #right_eye_grayValue = img[right_eye2[1]:right_eye4[1],right_eye1[0]:right_eye2[0]].mean()\n",
        "    right_eye_grayValue = img[xCenter,yCenter]\n",
        "    features.append(right_eye_grayValue)\n",
        "\n",
        "    # cv2.rectangle(imgcolor, (right_eye1[0], right_eye2[1]), (right_eye2[0], right_eye4[1]), (0, 255, 0), 2)\n",
        "\n",
        "    # imgplot = plt.imshow(imgcolor)\n",
        "    # imgplot2 = plt.imshow(right_eye)\n",
        "    # plt.show()\n",
        "\n",
        "    norm = np.linalg.norm(features)\n",
        "    normal_array = features/norm\n",
        "    return normal_array\n",
        "\n",
        "def read_img(path, detector, predictor):\n",
        "    #print(path)\n",
        "    # img = image.load_img(path, target_size=(224, 224))\n",
        "    img = cv2.imread(path, 0)\n",
        "    imgcolor = cv2.imread(path)\n",
        "    \n",
        "    rects = detector(img, 1)\n",
        "    for (i, rect) in enumerate(rects):\n",
        "      shape = predictor(img, rect)\n",
        "      shape = face_utils.shape_to_np(shape)\n",
        "      features = extractFeatures(shape, img, imgcolor)\n",
        "      return np.array(features)  \n",
        "      break\n",
        "\n",
        "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
        "    ppl = list(person_to_images_map.keys())\n",
        "    while True:\n",
        "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
        "        labels = [1] * len(batch_tuples)\n",
        "        while len(batch_tuples) < batch_size:\n",
        "            p1 = choice(ppl)\n",
        "            p2 = choice(ppl)\n",
        "\n",
        "            if p1 != p2 and (p1, p2) not in list_tuples and (p2, p1) not in list_tuples:\n",
        "                batch_tuples.append((p1, p2))\n",
        "                labels.append(0)\n",
        "\n",
        "        for x in batch_tuples:\n",
        "            if not len(person_to_images_map[x[0]]):\n",
        "                print(x[0])\n",
        "        detector = dlib.get_frontal_face_detector()\n",
        "        predictor = dlib.shape_predictor('drive/My Drive/shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
        "        X1 = np.array([read_img(x, detector, predictor) for x in X1])\n",
        "\n",
        "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
        "        X2 = np.array([read_img(x, detector, predictor) for x in X2])\n",
        "\n",
        "        distances = []\n",
        "        labelscpy = labels\n",
        "        for i in range(len(labels) - 1, -1, -1):\n",
        "          try:\n",
        "              #print(sklearn.metrics.pairwise.cosine_similarity(X1[i].reshape(1, -1), X2[i].reshape(1, -1))[0])\n",
        "              #print(labels[i])\n",
        "              #distances.append(sklearn.metrics.pairwise.cosine_similarity(X1[i].reshape(1, -1), X2[i].reshape(1, -1))[0])\n",
        "              distances.append(np.absolute(np.array(X1[i]) - np.array(X2[i])))\n",
        "          except:\n",
        "            del labels [i]\n",
        "        return distances, labels\n",
        "\n",
        "\n",
        "def computeHOG(image):\n",
        "    winSize = (64, 64)\n",
        "    blockSize = (16, 16)\n",
        "    blockStride = (8, 8)\n",
        "    cellSize = (8, 8)\n",
        "    nbins = 9\n",
        "    derivAperture = 1\n",
        "    winSigma = 4.\n",
        "    histogramNormType = 0\n",
        "    L2HysThreshold = 2.0000000000000001e-01\n",
        "    gammaCorrection = 0\n",
        "    nlevels = 64\n",
        "    hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins, derivAperture, winSigma,\n",
        "                            histogramNormType, L2HysThreshold, gammaCorrection, nlevels)\n",
        "    # compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
        "    winStride = (8, 8)\n",
        "    padding = (8, 8)\n",
        "    locations = ((10, 20),)\n",
        "    hist = hog.compute(image, winStride, padding, locations)\n",
        "    return hist\n",
        "\n",
        "\n",
        "# ------------------------------- MODEL --------------------------------\n",
        "\n",
        "model = sklearn.neighbors.KNeighborsClassifier()\n",
        "\n",
        "#for i in range(val_families_list.__len__()):\n",
        "train, val, train_person_to_images_map, val_person_to_images_map = get_train_val(val_families_list[0])\n",
        "data = gen(train, train_person_to_images_map, batch_size=2000)\n",
        "val_data = gen(val, val_person_to_images_map, batch_size=200)\n",
        "print(len(data[0]))\n",
        "print(len(val_data[0]))\n",
        "model.fit(data[0], data[1])\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        "y_pred = model.predict(val_data[0])\n",
        "print(\"Accuracy:\", metrics.accuracy_score(val_data[1], y_pred))\n",
        "\n",
        "# print(all_images.__len__())\n",
        "# # history = model.fit(gen(train, train_person_to_images_map, batch_size=16))\n",
        "#\n",
        "# n_samples = all_images.__len__()\n",
        "# cv = ShuffleSplit(n_splits=5, test_size=0.1, random_state=0)\n",
        "# cross_val_score(model, all_images, all_person_to_images_map, cv=cv)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1872\n",
            "191\n",
            "Accuracy: 0.49214659685863876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8fja1keJMUR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf3ead2b-5d2c-4c5c-f1f3-17de20c900fd"
      },
      "source": [
        "!pip install dlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.6/dist-packages (19.18.0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}